{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UniBiCLSTM",
      "provenance": [],
      "collapsed_sections": [
        "lcNWTdunEuFz"
      ],
      "authorship_tag": "ABX9TyMOsfnu8MjuIOnEH6eMp/bw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReserachOnDeepLearning/UniBiCLSTM/blob/main/UniBiCLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training process"
      ],
      "metadata": {
        "id": "5rzlgdANtGgR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcNWTdunEuFz"
      },
      "source": [
        "## Training Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "55w8DcOdxmUu",
        "outputId": "e6fb2fdd-e616-48c5-9d72-477dc6806ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------Donkey car Training environment--Start-------------------------------------------------------------\n",
            "Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "  Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "  Downloading tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 345.0 MB 4.3 kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.5.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.47.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (3.17.3)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.21.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.8.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n",
            "Found existing installation: numpy 1.21.6\n",
            "Uninstalling numpy-1.21.6:\n",
            "  Successfully uninstalled numpy-1.21.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 11.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, which is not installed.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras 2.8.0\n",
            "Uninstalling keras-2.8.0:\n",
            "  Successfully uninstalled keras-2.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.6.0\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 12.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "Successfully installed keras-2.6.0\n",
            "----------------------------------------------------Donkey car Training environment--successfully-------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------Donkey car Source download--Start-------------------------------------------------------------------\n",
            "Cloning into 'donkeycar'...\n",
            "remote: Enumerating objects: 2990, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 2990 (delta 15), reused 3 (delta 1), pack-reused 2941\u001b[K\n",
            "Receiving objects: 100% (2990/2990), 365.73 MiB | 15.94 MiB/s, done.\n",
            "Resolving deltas: 100% (1116/1116), done.\n",
            "Checking out files: 100% (2654/2654), done.\n",
            "/content/donkeycar\n",
            "/content/donkeycar/donkeycar\n",
            "----------------------------------------------------Donkey car Source download--successfully------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------Donkey car Software installation-Start--------------------------------------------------------------\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/donkeycar/donkeycar\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (1.20.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (7.1.2)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (5.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (3.1.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (0.2.3.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (1.3.5)\n",
            "Requirement already satisfied: PrettyTable in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (3.3.0)\n",
            "Collecting paho-mqtt\n",
            "  Downloading paho-mqtt-1.6.1.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from donkeycar==3.1.1) (3.2.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->donkeycar==3.1.1) (1.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->donkeycar==3.1.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->donkeycar==3.1.1) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->donkeycar==3.1.1) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->donkeycar==3.1.1) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->donkeycar==3.1.1) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->donkeycar==3.1.1) (1.15.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->donkeycar==3.1.1) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->donkeycar==3.1.1) (2.9.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->donkeycar==3.1.1) (4.64.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->donkeycar==3.1.1) (2022.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable->donkeycar==3.1.1) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from PrettyTable->donkeycar==3.1.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->PrettyTable->donkeycar==3.1.1) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->donkeycar==3.1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->donkeycar==3.1.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->donkeycar==3.1.1) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->donkeycar==3.1.1) (2.10)\n",
            "Building wheels for collected packages: docopt, paho-mqtt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=b80c25d0629758fea849f4085d535fba8fd6db50a72259b4ec5d74148996a652\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.6.1-py3-none-any.whl size=62133 sha256=6384bad95e6f06536ad15278f01ceafeb7b28c5788926515192f042ffec97787\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/bf/ac/2b3f43f8c6fcd0f4ba5395397458c521eb0b52d33b574a5a40\n",
            "Successfully built docopt paho-mqtt\n",
            "Installing collected packages: paho-mqtt, docopt, donkeycar\n",
            "  Running setup.py develop for donkeycar\n",
            "Successfully installed docopt-0.6.2 donkeycar-3.1.1 paho-mqtt-1.6.1\n",
            "----------------------------------------------------Donkey car Software installation-successfully-------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------Create the working directory of the car application-- Start-----------------------------------------\n",
            "using donkey v3.1.1 ...\n",
            "Creating car folder: /content/mycar\n",
            "making dir  /content/mycar\n",
            "Creating data & model folders.\n",
            "making dir  /content/mycar/models\n",
            "making dir  /content/mycar/data\n",
            "making dir  /content/mycar/logs\n",
            "Copying car application template: complete\n",
            "Copying car config defaults. Adjust these before starting your car.\n",
            "Copying train script. Adjust these before starting your car.\n",
            "Copying my car config overrides\n",
            "Donkey setup complete.\n",
            "----------------------------------------------------The working directory of the car application was created--Successfully------------------------------\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"----------------------------------------------------Donkey car Training environment--Start-------------------------------------------------------------\")\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==1.13.1\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.20.3\n",
        "!pip uninstall -y keras\n",
        "!pip install keras==2.6.0\n",
        "print(\"----------------------------------------------------Donkey car Training environment--successfully-------------------------------------------------------\")\n",
        "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"----------------------------------------------------Donkey car Source download--Start-------------------------------------------------------------------\")\n",
        "!git clone https://github.com/ReserachOnDeepLearning/SmartCar.git donkeycar\n",
        "%cd donkeycar\n",
        "%cd /content/donkeycar/donkeycar\n",
        "print(\"----------------------------------------------------Donkey car Source download--successfully------------------------------------------------------------\")\n",
        "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"----------------------------------------------------Donkey car Software installation-Start--------------------------------------------------------------\")\n",
        "!pip3 install -e .[pc]\n",
        "print(\"----------------------------------------------------Donkey car Software installation-successfully-------------------------------------------------------\")\n",
        "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"----------------------------------------------------Create the working directory of the car application-- Start-----------------------------------------\")\n",
        "!donkey createcar --path /content/mycar\n",
        "print(\"----------------------------------------------------The working directory of the car application was created--Successfully------------------------------\")\n",
        "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/donkeycar/donkeycar/donkeycar/parts/keras.py\n",
        "!cp /content/donkeycar/keras.py /content/donkeycar/donkeycar/donkeycar/parts/keras.py"
      ],
      "metadata": {
        "id": "cfc6CJq7IEJB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Model Training"
      ],
      "metadata": {
        "id": "4PvdioY_61-H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiS3zwRzPd0n",
        "outputId": "3fc8b6e0-4e26-41ab-a8cb-688727210663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------Data set loaded Start-------------------------------------------------------------------------------\n",
            "Data set loading......\n",
            "Task Complete\n",
            "Mapp_1_7000    Mapp_3_2_1000   Mapp_3_B2_2000\t     Mapp_4_5000\n",
            "Mapp_2_3000    Mapp_3_3_3000   Mapp_3_Object_1_3600\n",
            "Mapp_3_1_3500  Mapp_3_B1_2000  Mapp_3_Object_2_3600\n",
            "----------------------------------------------------Data set loaded successfully------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"----------------------------------------------------Data set loaded Start-------------------------------------------------------------------------------\")\n",
        "!rm -rf /content/mycar/data\n",
        "!mkdir  /content/mycar/data\n",
        "print(\"Data set loading......\")\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_1_7000.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_2_3000.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_3_1_3500.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_3_2_1000.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_3_3_3000.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_3_B1_2000.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_3_B2_2000.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_3_Object_1_3600.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_3_Object_2_3600.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/Datasets/Mapp_4_5000.zip -d /content/mycar/data\n",
        "print(\"Task Complete\")\n",
        "!ls /content/mycar/data\n",
        "print(\"----------------------------------------------------Data set loaded successfully------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----------------------------------------------------Training Start--------------------------------------------------------------------------------------\")\n",
        "!python /content/mycar/manage.py train \\\n",
        "    --type=rnn \\\n",
        "    --tub=/content/mycar/data/* \\\n",
        "    --model=/content/UniBiCLSTM.h5\n",
        "print(\"----------------------------------------------------Training Ended--------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkLzh-uy62HW",
        "outputId": "c90cf91d-bc47-4d8c-83a5-d657e91f058f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------Training Start--------------------------------------------------------------------------------------\n",
            "using donkey v3.1.1 ...\n",
            "loading config file: /content/mycar/config.py\n",
            "loading personal config over-rides\n",
            "\n",
            "config loaded\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "2022-08-03 15:13:13.601274: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2022-08-03 15:13:13.647751: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000129999 Hz\n",
            "2022-08-03 15:13:13.648080: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2b2dfa0 executing computations on platform Host. Devices:\n",
            "2022-08-03 15:13:13.648115: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2022-08-03 15:13:13.889929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-03 15:13:13.890661: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2b2db80 executing computations on platform CUDA. Devices:\n",
            "2022-08-03 15:13:13.890693: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-08-03 15:13:13.891831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.75GiB freeMemory: 14.66GiB\n",
            "2022-08-03 15:13:13.891860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2022-08-03 15:13:13.892826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-03 15:13:13.892872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2022-08-03 15:13:13.892885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2022-08-03 15:13:13.893068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "sequence of images training\n",
            "\"get_model_by_type\" model Type is: rnn\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Tub: /content/mycar/data/Mapp_3_B1_2000 has 2000 records\n",
            "Tub: /content/mycar/data/Mapp_2_3000 has 3000 records\n",
            "Tub: /content/mycar/data/Mapp_3_1_3500 has 3500 records\n",
            "Tub: /content/mycar/data/Mapp_3_3_3000 has 3000 records\n",
            "Tub: /content/mycar/data/Mapp_4_5000 has 5000 records\n",
            "Tub: /content/mycar/data/Mapp_1_7000 has 7000 records\n",
            "Tub: /content/mycar/data/Mapp_3_2_1000 has 1000 records\n",
            "Tub: /content/mycar/data/Mapp_3_Object_2_3600 has 3600 records\n",
            "Tub: /content/mycar/data/Mapp_3_B2_2000 has 2000 records\n",
            "Tub: /content/mycar/data/Mapp_3_Object_1_3600 has 3600 records\n",
            "collating records\n",
            "collating sequences\n",
            "collated 33680 sequences of length 3\n",
            "train: 26944, validation: 6736\n",
            "steps_per_epoch 210\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "2022-08-03 15:13:37.240239: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "52/52 [==============================] - 5s 93ms/step - loss: 0.2524\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.25245, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 59s 280ms/step - loss: 0.2671 - val_loss: 0.2524\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 4s 69ms/step - loss: 0.0996\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.25245 to 0.09957, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 34s 160ms/step - loss: 0.1614 - val_loss: 0.0996\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0642\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.09957 to 0.06417, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 34s 161ms/step - loss: 0.0816 - val_loss: 0.0642\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0557\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.06417 to 0.05571, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0642 - val_loss: 0.0557\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0510\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.05571 to 0.05105, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 159ms/step - loss: 0.0568 - val_loss: 0.0510\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0475\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.05105 to 0.04750, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0523 - val_loss: 0.0475\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 4s 69ms/step - loss: 0.0459\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.04750 to 0.04590, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 34s 160ms/step - loss: 0.0490 - val_loss: 0.0459\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0447\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.04590 to 0.04471, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 159ms/step - loss: 0.0465 - val_loss: 0.0447\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0441\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.04471 to 0.04408, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0456 - val_loss: 0.0441\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 4s 67ms/step - loss: 0.0424\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.04408 to 0.04236, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0435 - val_loss: 0.0424\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 4s 69ms/step - loss: 0.0398\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.04236 to 0.03981, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 34s 160ms/step - loss: 0.0429 - val_loss: 0.0398\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0394\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.03981 to 0.03937, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0426 - val_loss: 0.0394\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0393\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.03937 to 0.03929, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0403 - val_loss: 0.0393\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0379\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.03929 to 0.03789, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0400 - val_loss: 0.0379\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 3s 67ms/step - loss: 0.0394\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.03789\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0380 - val_loss: 0.0394\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0378\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.03789 to 0.03782, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 34s 160ms/step - loss: 0.0378 - val_loss: 0.0378\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 4s 69ms/step - loss: 0.0367\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.03782 to 0.03671, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0373 - val_loss: 0.0367\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 4s 67ms/step - loss: 0.0340\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.03671 to 0.03400, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 159ms/step - loss: 0.0365 - val_loss: 0.0340\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0354\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.03400\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0354 - val_loss: 0.0354\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 4s 69ms/step - loss: 0.0369\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.03400\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0358 - val_loss: 0.0369\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 3s 67ms/step - loss: 0.0327\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.03400 to 0.03268, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0348 - val_loss: 0.0327\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0360\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.03268\n",
            "210/210 [==============================] - 33s 159ms/step - loss: 0.0373 - val_loss: 0.0360\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 4s 68ms/step - loss: 0.0343\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.03268\n",
            "210/210 [==============================] - 33s 157ms/step - loss: 0.0344 - val_loss: 0.0343\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 3s 67ms/step - loss: 0.0333\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.03268\n",
            "210/210 [==============================] - 33s 158ms/step - loss: 0.0344 - val_loss: 0.0333\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 4s 67ms/step - loss: 0.0333\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.03268\n",
            "210/210 [==============================] - 33s 157ms/step - loss: 0.0339 - val_loss: 0.0333\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 4s 67ms/step - loss: 0.0320\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.03268 to 0.03200, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 157ms/step - loss: 0.0326 - val_loss: 0.0320\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 3s 67ms/step - loss: 0.0298\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.03200 to 0.02983, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 157ms/step - loss: 0.0329 - val_loss: 0.0298\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 4s 67ms/step - loss: 0.0307\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.02983\n",
            "210/210 [==============================] - 33s 156ms/step - loss: 0.0312 - val_loss: 0.0307\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 3s 67ms/step - loss: 0.0324\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.02983\n",
            "210/210 [==============================] - 33s 157ms/step - loss: 0.0315 - val_loss: 0.0324\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 3s 67ms/step - loss: 0.0300\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.02983\n",
            "210/210 [==============================] - 33s 157ms/step - loss: 0.0310 - val_loss: 0.0300\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 3s 66ms/step - loss: 0.0294\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.02983 to 0.02940, saving model to /content/UniBiCLSTM.h5\n",
            "210/210 [==============================] - 33s 157ms/step - loss: 0.0311 - val_loss: 0.0294\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 4s 67ms/step - loss: 0.0316\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.02940\n",
            "210/210 [==============================] - 33s 157ms/step - loss: 0.0309 - val_loss: 0.0316\n",
            "Epoch 00032: early stopping\n",
            "Training completed in 0:18:13.\n",
            "\n",
            "\n",
            "----------- Best Eval Loss :0.029401 ---------\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "----------------------------------------------------Training Ended--------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Laarning"
      ],
      "metadata": {
        "id": "ByFpiDj-wOjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----------------------------------------------------Data set loaded Start-------------------------------------------------------------------------------\")\n",
        "!rm -rf /content/mycar/data\n",
        "!mkdir  /content/mycar/data\n",
        "print(\"Data set loading......\")\n",
        "!unzip -uq /content/donkeycar/mycar/D2/D1.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/D2/D2.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/D2/D3.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/D2/D11.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/D2/D22.zip -d /content/mycar/data\n",
        "!unzip -uq /content/donkeycar/mycar/D2/D33.zip -d /content/mycar/data\n",
        "print(\"Task Complete\")\n",
        "!ls /content/mycar/data\n",
        "print(\"----------------------------------------------------Data set loaded successfully------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTmp5OpkLsci",
        "outputId": "7473e833-9a25-485a-9734-0b326dac6000"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------Data set loaded Start-------------------------------------------------------------------------------\n",
            "Data set loading......\n",
            "Task Complete\n",
            "D1  D11  D2  D22  D3  D33\n",
            "----------------------------------------------------Data set loaded successfully------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----------------------------------------------------Modify myconfig-------------------------------------------------------------------------------------\")\n",
        "!rm -rf /content/mycar/myconfig.py\n",
        "!cp /content/donkeycar/mycar/myconfig.py /content/mycar\n",
        "print(\"----------------------------------------------------Modify myconfig successful--------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"----------------------------------------------------Modify Losses---------------------------------------------------------------------------------------\")\n",
        "!rm -rf /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py\n",
        "!cp /content/donkeycar/mycar/losses.py /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras\n",
        "print(\"----------------------------------------------------Modify Losses successful----------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"----------------------------------------------------Modify saving---------------------------------------------------------------------------------------\")\n",
        "!rm -rf /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/saving.py\n",
        "!cp /content/donkeycar/mycar/saving.py /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine\n",
        "print(\"----------------------------------------------------Modify saving successful----------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"----------------------------------------------------Training Start--------------------------------------------------------------------------------------\")\n",
        "!python /content/mycar/manage.py train \\\n",
        "    --type=rnn \\\n",
        "    --tub=/content/mycar/data/* \\\n",
        "    --transfer=/content/donkeycar/mycar/UniBiCLSTM.h5  \\\n",
        "    --model=/content/CMTL-UniBiRL-CL.h5\n",
        "print(\"----------------------------------------------------Training Ended--------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VugUYVteLH_a",
        "outputId": "45628fc3-8f20-49e9-e667-3d9453ab0c72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------Modify myconfig-------------------------------------------------------------------------------------\n",
            "----------------------------------------------------Modify myconfig successful--------------------------------------------------------------------------\n",
            "----------------------------------------------------Modify Losses---------------------------------------------------------------------------------------\n",
            "----------------------------------------------------Modify Losses successful----------------------------------------------------------------------------\n",
            "----------------------------------------------------Modify saving---------------------------------------------------------------------------------------\n",
            "----------------------------------------------------Modify saving successful----------------------------------------------------------------------------\n",
            "----------------------------------------------------Training Start--------------------------------------------------------------------------------------\n",
            "using donkey v3.1.1 ...\n",
            "loading config file: /content/mycar/config.py\n",
            "loading personal config over-rides\n",
            "\n",
            "config loaded\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "2022-08-03 16:03:53.171888: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2022-08-03 16:03:53.175899: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000129999 Hz\n",
            "2022-08-03 16:03:53.176132: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2567fa0 executing computations on platform Host. Devices:\n",
            "2022-08-03 16:03:53.176164: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2022-08-03 16:03:53.330865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-03 16:03:53.331678: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2567b80 executing computations on platform CUDA. Devices:\n",
            "2022-08-03 16:03:53.331710: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-08-03 16:03:53.331856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.75GiB freeMemory: 14.66GiB\n",
            "2022-08-03 16:03:53.331882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2022-08-03 16:03:53.332745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-03 16:03:53.332770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2022-08-03 16:03:53.332780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2022-08-03 16:03:53.332861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "sequence of images training\n",
            "\"get_model_by_type\" model Type is: rnn\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Tub: /content/mycar/data/D33 has 6319 records\n",
            "Tub: /content/mycar/data/D2 has 6319 records\n",
            "Tub: /content/mycar/data/D1 has 6000 records\n",
            "Tub: /content/mycar/data/D11 has 2000 records\n",
            "Tub: /content/mycar/data/D22 has 6000 records\n",
            "Tub: /content/mycar/data/D3 has 2000 records\n",
            "collating records\n",
            "collating sequences\n",
            "collated 27627 sequences of length 3\n",
            "train: 22102, validation: 5525\n",
            "steps_per_epoch 172\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "2022-08-03 16:04:07.310544: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "43/43 [==============================] - 4s 94ms/step - loss: 0.0631\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.06310, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 41s 238ms/step - loss: 0.0876 - val_loss: 0.0631\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0398\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.06310 to 0.03979, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0489 - val_loss: 0.0398\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0349\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.03979 to 0.03491, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0385 - val_loss: 0.0349\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0304\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.03491 to 0.03036, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0361 - val_loss: 0.0304\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0306\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.03036\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0334 - val_loss: 0.0306\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0280\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.03036 to 0.02801, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0320 - val_loss: 0.0280\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0262\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.02801 to 0.02624, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 157ms/step - loss: 0.0301 - val_loss: 0.0262\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0258\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.02624 to 0.02583, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 157ms/step - loss: 0.0289 - val_loss: 0.0258\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0237\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.02583 to 0.02372, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0282 - val_loss: 0.0237\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0257\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.02372\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0268 - val_loss: 0.0257\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0233\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.02372 to 0.02329, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0261 - val_loss: 0.0233\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0217\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.02329 to 0.02175, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 158ms/step - loss: 0.0256 - val_loss: 0.0217\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0220\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.02175\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0246 - val_loss: 0.0220\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0216\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.02175 to 0.02162, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 157ms/step - loss: 0.0242 - val_loss: 0.0216\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0207\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.02162 to 0.02065, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0232 - val_loss: 0.0207\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0200\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.02065 to 0.01999, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0226 - val_loss: 0.0200\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0212\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01999\n",
            "172/172 [==============================] - 27s 157ms/step - loss: 0.0224 - val_loss: 0.0212\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 3s 66ms/step - loss: 0.0190\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01999 to 0.01898, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0224 - val_loss: 0.0190\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0187\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01898 to 0.01869, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0216 - val_loss: 0.0187\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0196\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01869\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0213 - val_loss: 0.0196\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0189\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01869\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0209 - val_loss: 0.0189\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0181\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01869 to 0.01809, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 157ms/step - loss: 0.0201 - val_loss: 0.0181\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0171\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01809 to 0.01715, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0205 - val_loss: 0.0171\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0180\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01715\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0197 - val_loss: 0.0180\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0165\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.01715 to 0.01650, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0190 - val_loss: 0.0165\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0181\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01650\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0189 - val_loss: 0.0181\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0164\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01650 to 0.01643, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 157ms/step - loss: 0.0186 - val_loss: 0.0164\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0167\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01643\n",
            "172/172 [==============================] - 27s 154ms/step - loss: 0.0183 - val_loss: 0.0167\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0164\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01643\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0175 - val_loss: 0.0164\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 3s 66ms/step - loss: 0.0156\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.01643 to 0.01556, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0174 - val_loss: 0.0156\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0158\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01556\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0171 - val_loss: 0.0158\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0153\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.01556 to 0.01526, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0169 - val_loss: 0.0153\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0154\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01526\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0172 - val_loss: 0.0154\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0165\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01526\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0168 - val_loss: 0.0165\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.0140\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.01526 to 0.01401, saving model to /content/CMTL-UniBiRL-CL.h5\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0167 - val_loss: 0.0140\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 3s 66ms/step - loss: 0.0163\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01401\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0166 - val_loss: 0.0163\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0152\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01401\n",
            "172/172 [==============================] - 27s 156ms/step - loss: 0.0162 - val_loss: 0.0152\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0146\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01401\n",
            "172/172 [==============================] - 27s 155ms/step - loss: 0.0159 - val_loss: 0.0146\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 3s 66ms/step - loss: 0.0145\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01401\n",
            "172/172 [==============================] - 27s 154ms/step - loss: 0.0158 - val_loss: 0.0145\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.0141\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01401\n",
            "172/172 [==============================] - 26s 154ms/step - loss: 0.0157 - val_loss: 0.0141\n",
            "Epoch 00040: early stopping\n",
            "Training completed in 0:18:09.\n",
            "\n",
            "\n",
            "----------- Best Eval Loss :0.014011 ---------\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "----------------------------------------------------Training Ended--------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "Test code.\n",
        "Do not execute code."
      ],
      "metadata": {
        "id": "yoT34qfH7MPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/mycar/config.py /content\n",
        "\n",
        "# import config as cfg\n",
        "# from tensorflow.python.keras.layers import Input, Dense\n",
        "# from tensorflow.python.keras.models import Model, Sequential\n",
        "# from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D, Reshape, BatchNormalization, Bidirectional\n",
        "# from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Cropping2D, Lambda\n",
        "# from tensorflow.python.keras.layers.merge import concatenate\n",
        "# from tensorflow.python.keras.layers import LSTM\n",
        "# from tensorflow.python.keras.layers.wrappers import TimeDistributed as TD\n",
        "# from tensorflow.python.keras.layers import Conv3D, MaxPooling3D, Cropping3D, Conv2DTranspose\n",
        "\n",
        "# class KerasPilot(object):\n",
        "#     '''\n",
        "#     Base class for Keras models that will provide steering and throttle to guide a car.\n",
        "#     '''\n",
        "#     def __init__(self):\n",
        "#         self.model = None\n",
        "#         self.optimizer = \"adam\"\n",
        " \n",
        "#     def load(self, model_path):\n",
        "#         self.model = keras.models.load_model(model_path)\n",
        "\n",
        "#     def load_weights(self, model_path, by_name=True):\n",
        "#         self.model.load_weights(model_path, by_name=by_name)\n",
        "\n",
        "#     def shutdown(self):\n",
        "#         pass\n",
        "\n",
        "#     def compile(self):\n",
        "#         pass\n",
        "\n",
        "#     def set_optimizer(self, optimizer_type, rate, decay):\n",
        "#         if optimizer_type == \"adam\":\n",
        "#             self.model.optimizer = keras.optimizers.Adam(lr=rate, decay=decay)\n",
        "#         elif optimizer_type == \"sgd\":\n",
        "#             self.model.optimizer = keras.optimizers.SGD(lr=rate, decay=decay)\n",
        "#         elif optimizer_type == \"rmsprop\":\n",
        "#             self.model.optimizer = keras.optimizers.RMSprop(lr=rate, decay=decay)\n",
        "#         else:\n",
        "#             raise Exception(\"unknown optimizer type: %s\" % optimizer_type)\n",
        "    \n",
        "#     def train(self, train_gen, val_gen, \n",
        "#               saved_model_path, epochs=100, steps=100, train_split=0.8,\n",
        "#               verbose=1, min_delta=.0005, patience=5, use_early_stop=True):\n",
        "        \n",
        "#         \"\"\"\n",
        "#         train_gen: generator that yields an array of images an array of \n",
        "        \n",
        "#         \"\"\"\n",
        "\n",
        "#         #checkpoint to save model after each epoch\n",
        "#         save_best = keras.callbacks.ModelCheckpoint(saved_model_path, \n",
        "#                                                     monitor='val_loss', \n",
        "#                                                     verbose=verbose, \n",
        "#                                                     save_best_only=True, \n",
        "#                                                     mode='min')\n",
        "        \n",
        "#         #stop training if the validation error stops improving.\n",
        "#         early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "#                                                    min_delta=min_delta, \n",
        "#                                                    patience=patience, \n",
        "#                                                    verbose=verbose, \n",
        "#                                                    mode='auto')\n",
        "        \n",
        "#         callbacks_list = [save_best]\n",
        "\n",
        "#         if use_early_stop:\n",
        "#             callbacks_list.append(early_stop)\n",
        "        \n",
        "#         hist = self.model.fit_generator(\n",
        "#                         train_gen, \n",
        "#                         steps_per_epoch=steps, \n",
        "#                         epochs=epochs, \n",
        "#                         verbose=1, \n",
        "#                         validation_data=val_gen,\n",
        "#                         callbacks=callbacks_list, \n",
        "#                         validation_steps=steps*(1.0 - train_split))\n",
        "#         return hist\n",
        "\n",
        "# class UniBiCLSTM(KerasPilot):\n",
        "#     def __init__(self, image_w =160, image_h=120, image_d=3, seq_length=3, num_outputs=2, *args, **kwargs):\n",
        "#         super(UniBiCLSTM, self).__init__(*args, **kwargs)\n",
        "#         image_shape = (image_h, image_w, image_d)\n",
        "#         self.model = unibiclstm(seq_length=seq_length,\n",
        "#             num_outputs=num_outputs,\n",
        "#             image_shape=image_shape)\n",
        "#         self.seq_length = seq_length\n",
        "#         self.image_d = image_d\n",
        "#         self.image_w = image_w\n",
        "#         self.image_h = image_h\n",
        "#         self.img_seq = []\n",
        "#         self.compile()\n",
        "#         self.optimizer = \"rmsprop\"\n",
        "\n",
        "#     def compile(self):\n",
        "#         self.model.compile(optimizer=self.optimizer,\n",
        "#                   loss='mse')\n",
        "\n",
        "#     def run(self, img_arr):\n",
        "#         if img_arr.shape[2] == 3 and self.image_d == 1:\n",
        "#             img_arr = dk.utils.rgb2gray(img_arr)\n",
        "\n",
        "#         while len(self.img_seq) < self.seq_length:\n",
        "#             self.img_seq.append(img_arr)\n",
        "\n",
        "#         self.img_seq = self.img_seq[1:]\n",
        "#         self.img_seq.append(img_arr)\n",
        "        \n",
        "#         img_arr = np.array(self.img_seq).reshape(1, self.seq_length, self.image_h, self.image_w, self.image_d )\n",
        "#         outputs = self.model.predict([img_arr])\n",
        "#         steering = outputs[0][0]\n",
        "#         throttle = outputs[0][1]\n",
        "#         return steering, throttle\n",
        "  \n",
        "\n",
        "# def unibiclstm(seq_length=3, num_outputs=2, image_shape=(120,160,3)):\n",
        "\n",
        "#     #we now expect that cropping done elsewhere. we will adjust our expeected image size here:\n",
        "#     #input_shape = adjust_input_shape(input_shape, roi_crop)\n",
        "\n",
        "#     img_seq_shape = (seq_length,) + image_shape   \n",
        "#     img_in = Input(batch_shape = img_seq_shape, name='img_in')\n",
        "#     drop_out = 0.3\n",
        "\n",
        "#     x = Sequential()\n",
        "#     x.add(TD(Convolution2D(26, (5,5), strides=(2,2), activation='relu'), input_shape=img_seq_shape))\n",
        "#     x.add(TD(Dropout(drop_out)))\n",
        "#     x.add(TD(Convolution2D(48, (5,5), strides=(2,2), activation='relu')))\n",
        "#     x.add(TD(Dropout(drop_out)))\n",
        "#     x.add(TD(Convolution2D(64, (3,3), strides=(2,2), activation='relu')))\n",
        "#     x.add(TD(Dropout(drop_out)))\n",
        "#     x.add(TD(Convolution2D(64, (3,3), strides=(1,1), activation='relu')))\n",
        "#     x.add(TD(Dropout(drop_out)))\n",
        "#     x.add(TD(MaxPooling2D(pool_size=(2, 2))))\n",
        "#     x.add(TD(Flatten(name='flattened')))\n",
        "#     x.add(TD(Dense(100, activation='relu')))\n",
        "#     x.add(TD(Dropout(drop_out)))\n",
        "      \n",
        "#     x.add(Bidirectional(LSTM(128, return_sequences=True, name=\"LSTM_seq\")))\n",
        "#     x.add(Dropout(.1))\n",
        "#     x.add(Bidirectional(LSTM(128, return_sequences=True, name=\"LSTM_seq1\")))\n",
        "#     x.add(Dropout(.1))\n",
        "#     x.add(LSTM(128, return_sequences=False, name=\"LSTM_fin\"))\n",
        "#     x.add(Dropout(.1))\n",
        "#     x.add(Dense(128, activation='relu'))\n",
        "#     x.add(Dropout(.1))\n",
        "#     x.add(Dense(64, activation='relu'))\n",
        "#     x.add(Dense(10, activation='relu'))\n",
        "#     x.add(Dense(num_outputs, activation='linear', name='model_outputs'))\n",
        "    \n",
        "#     return x\n",
        "\n",
        "# kl = UniBiCLSTM(image_w=cfg.IMAGE_W, image_h=cfg.IMAGE_H, image_d=cfg.IMAGE_DEPTH, seq_length=cfg.SEQUENCE_LENGTH)\n",
        "\n",
        "# print(kl.model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQXOEQU07MXI",
        "outputId": "4835803c-5f2a-495e-a5f5-3db0f7e8d3a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 3, 58, 78, 26)     1976      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 3, 58, 78, 26)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 3, 27, 37, 48)     31248     \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 3, 27, 37, 48)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 3, 13, 18, 64)     27712     \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 3, 13, 18, 64)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 3, 11, 16, 64)     36928     \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 3, 11, 16, 64)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 3, 5, 8, 64)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 3, 2560)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 3, 100)            256100    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 3, 256)            234496    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 256)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 3, 256)            394240    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 3, 256)            0         \n",
            "_________________________________________________________________\n",
            "LSTM_fin (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "model_outputs (Dense)        (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 1,205,260\n",
            "Trainable params: 1,205,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/mycar/config.py /content\n",
        "\n",
        "# import config as cfg\n",
        "# from tensorflow.python.keras.layers import Input, Dense\n",
        "# from tensorflow.python.keras.models import Model, Sequential\n",
        "# from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D, Reshape, BatchNormalization, Bidirectional\n",
        "# from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Cropping2D, Lambda\n",
        "# from tensorflow.python.keras.layers.merge import concatenate\n",
        "# from tensorflow.python.keras.layers import LSTM\n",
        "# from tensorflow.python.keras.layers.wrappers import TimeDistributed as TD\n",
        "# from tensorflow.python.keras.layers import Conv3D, MaxPooling3D, Cropping3D, Conv2DTranspose, SimpleRNN, LSTM\n",
        "\n",
        "# class KerasPilot(object):\n",
        "#     '''\n",
        "#     Base class for Keras models that will provide steering and throttle to guide a car.\n",
        "#     '''\n",
        "#     def __init__(self):\n",
        "#         self.model = None\n",
        "#         self.optimizer = \"adam\"\n",
        " \n",
        "#     def load(self, model_path):\n",
        "#         self.model = keras.models.load_model(model_path)\n",
        "\n",
        "#     def load_weights(self, model_path, by_name=True):\n",
        "#         self.model.load_weights(model_path, by_name=by_name)\n",
        "\n",
        "#     def shutdown(self):\n",
        "#         pass\n",
        "\n",
        "#     def compile(self):\n",
        "#         pass\n",
        "\n",
        "#     def set_optimizer(self, optimizer_type, rate, decay):\n",
        "#         if optimizer_type == \"adam\":\n",
        "#             self.model.optimizer = keras.optimizers.Adam(lr=rate, decay=decay)\n",
        "#         elif optimizer_type == \"sgd\":\n",
        "#             self.model.optimizer = keras.optimizers.SGD(lr=rate, decay=decay)\n",
        "#         elif optimizer_type == \"rmsprop\":\n",
        "#             self.model.optimizer = keras.optimizers.RMSprop(lr=rate, decay=decay)\n",
        "#         else:\n",
        "#             raise Exception(\"unknown optimizer type: %s\" % optimizer_type)\n",
        "    \n",
        "#     def train(self, train_gen, val_gen, \n",
        "#               saved_model_path, epochs=100, steps=100, train_split=0.8,\n",
        "#               verbose=1, min_delta=.0005, patience=5, use_early_stop=True):\n",
        "        \n",
        "#         \"\"\"\n",
        "#         train_gen: generator that yields an array of images an array of \n",
        "        \n",
        "#         \"\"\"\n",
        "\n",
        "#         #checkpoint to save model after each epoch\n",
        "#         save_best = keras.callbacks.ModelCheckpoint(saved_model_path, \n",
        "#                                                     monitor='val_loss', \n",
        "#                                                     verbose=verbose, \n",
        "#                                                     save_best_only=True, \n",
        "#                                                     mode='min')\n",
        "        \n",
        "#         #stop training if the validation error stops improving.\n",
        "#         early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "#                                                    min_delta=min_delta, \n",
        "#                                                    patience=patience, \n",
        "#                                                    verbose=verbose, \n",
        "#                                                    mode='auto')\n",
        "        \n",
        "#         callbacks_list = [save_best]\n",
        "\n",
        "#         if use_early_stop:\n",
        "#             callbacks_list.append(early_stop)\n",
        "        \n",
        "#         hist = self.model.fit_generator(\n",
        "#                         train_gen, \n",
        "#                         steps_per_epoch=steps, \n",
        "#                         epochs=epochs, \n",
        "#                         verbose=1, \n",
        "#                         validation_data=val_gen,\n",
        "#                         callbacks=callbacks_list, \n",
        "#                         validation_steps=steps*(1.0 - train_split))\n",
        "#         return hist\n",
        "\n",
        "# class UniBiRLSTM(KerasPilot):\n",
        "#     def __init__(self, image_w =160, image_h=120, image_d=3, seq_length=3, num_outputs=2, *args, **kwargs):\n",
        "#         super(UniBiRLSTM, self).__init__(*args, **kwargs)\n",
        "#         image_shape = (image_h, image_w, image_d)\n",
        "#         self.model = rnn(seq_length=seq_length,\n",
        "#             num_outputs=num_outputs,\n",
        "#             image_shape=image_shape)\n",
        "#         self.seq_length = seq_length\n",
        "#         self.image_d = image_d\n",
        "#         self.image_w = image_w\n",
        "#         self.image_h = image_h\n",
        "#         self.img_seq = []\n",
        "#         self.compile()\n",
        "#         self.optimizer = \"rmsprop\"\n",
        "\n",
        "#     def compile(self):\n",
        "#         self.model.compile(optimizer=self.optimizer,\n",
        "#                   loss='mse')\n",
        "\n",
        "#     def run(self, img_arr):\n",
        "#         if img_arr.shape[2] == 3 and self.image_d == 1:\n",
        "#             img_arr = dk.utils.rgb2gray(img_arr)\n",
        "\n",
        "#         while len(self.img_seq) < self.seq_length:\n",
        "#             self.img_seq.append(img_arr)\n",
        "\n",
        "#         self.img_seq = self.img_seq[1:]\n",
        "#         self.img_seq.append(img_arr)\n",
        "        \n",
        "#         img_arr = np.array(self.img_seq).reshape(1, self.seq_length, self.image_h, self.image_w, self.image_d )\n",
        "#         outputs = self.model.predict([img_arr])\n",
        "#         steering = outputs[0][0]\n",
        "#         throttle = outputs[0][1]\n",
        "#         return steering, throttle\n",
        "  \n",
        "\n",
        "# def rnn(seq_length=3, num_outputs=2, image_shape=(120,160,3)):\n",
        "\n",
        "#     #we now expect that cropping done elsewhere. we will adjust our expeected image size here:\n",
        "#     #input_shape = adjust_input_shape(input_shape, roi_crop)\n",
        "\n",
        "#     # img_seq_shape = (seq_length,) + image_shape   \n",
        "#     img_seq_shape = image_shape   \n",
        "#     img_in = Input(batch_shape = img_seq_shape, name='img_in')\n",
        "#     drop_out = 0.3\n",
        "\n",
        "#     x = Sequential()\n",
        "\n",
        "#     x.add(SimpleRNN(40,input_shape=(120,160), return_sequences = True))\n",
        "#     x.add(Activation('relu'))\n",
        "#     x.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "#     x.add(Dropout(.1))\n",
        "#     x.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "#     x.add(Dropout(.1))\n",
        "#     x.add(LSTM(20,return_sequences = False))\n",
        "#     x.add(Activation('relu'))\n",
        "\n",
        "#     x.add(Flatten(name='flattened'))\n",
        "#     x.add(Dense(500))\n",
        "#     x.add(Activation('relu'))\n",
        "#     x.add(Dense(400))\n",
        "#     x.add(Activation('relu'))\n",
        "#     x.add(Dense(300))\n",
        "#     x.add(Activation('relu'))\n",
        "#     x.add(Dense(200))\n",
        "#     x.add(Activation('relu'))\n",
        "#     x.add(Dense(100))\n",
        "#     x.add(Activation('relu'))\n",
        "\n",
        "#     x.add(Dense(num_outputs, activation='linear', name='model_outputs'))\n",
        "    \n",
        "#     return x\n",
        "\n",
        "\n",
        "# kl = UniBiRLSTM(image_w=cfg.IMAGE_W, image_h=cfg.IMAGE_H, image_d=cfg.IMAGE_DEPTH)\n",
        "\n",
        "# print(kl.model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrKncjYBQSEV",
        "outputId": "4f5e5199-dfc4-45df-9635-a8690b89600f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 120, 40)           8040      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 120, 40)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 120, 256)          173056    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 120, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 120, 256)          394240    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 120, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 20)                22160     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "flattened (Flatten)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               10500     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 400)               200400    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 300)               120300    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               60200     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "model_outputs (Dense)        (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 1,009,198\n",
            "Trainable params: 1,009,198\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}